{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis ver3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a derived and cleaned up version of Analysis_ver2, with a pipeline for the first version of the webapp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/tobiszuts/Windows/Data/Work/Insight/project\n"
     ]
    }
   ],
   "source": [
    "cd /home/tobiszuts/insight/project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning\n",
    "\n",
    "Get the data and start processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_load = \"Reddit_depression.p\"\n",
    "results = pickle.load( open(file_load, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PreProcessData(raw_data) :\n",
    "    \"\"\" This processes the post data, and can be used as \n",
    "    a template for the upload data.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    data_raw = pd.DataFrame(raw_data)\n",
    "    # some of these columns aren't being used to create features yet\n",
    "    extract_keys = ['id', 'author', 'score', 'num_comments', 'downs', 'ups', \n",
    "                'created_utc', 'title', 'selftext']\n",
    "    data = data_raw[sorted(extract_keys)].copy()\n",
    "    \n",
    "    # remove all rows without any valid text\n",
    "    data = data[data.selftext.map(len) > 0]\n",
    "            \n",
    "    dates = pd.to_datetime(data.created_utc, unit=\"s\")\n",
    "    data['created_dayofweek'] = dates.dt.dayofweek\n",
    "    data['created_hour'] = dates.dt.hour\n",
    "    data['created_month'] = dates.dt.month\n",
    "    data['created_year'] = dates.dt.year\n",
    "    cut_off_year = 2011\n",
    "    data = data[ data.created_year > cut_off_year]\n",
    "    print('Removing all posts before 2011.')\n",
    "    \n",
    "    data['post_char_len'] = data.selftext.apply(lambda x: len(x))\n",
    "    data['post_num_qs'] = data.selftext.apply(lambda x: x.count('?'))\n",
    "    data['title_char_len'] = data.title.apply(lambda x: len(x))\n",
    "    data['title_num_qs'] = data.title.apply(lambda x: x.count('?'))\n",
    "    \n",
    "    def CountPostPunctuation(row) :\n",
    "        # count the number of punctuation in the selftext\n",
    "        import string\n",
    "        punc_set = set(string.punctuation)\n",
    "        num_punc = 0\n",
    "        for char in row['selftext'] :\n",
    "            if char in punc_set :\n",
    "                num_punc += 1\n",
    "        return num_punc\n",
    "    def CountTitlePunctuation(row) :\n",
    "        # count the number of punctuation in the selftext\n",
    "        import string\n",
    "        punc_set = set(string.punctuation)\n",
    "        num_punc = 0\n",
    "        for char in row['title'] :\n",
    "            if char in punc_set :\n",
    "                num_punc += 1\n",
    "        return num_punc\n",
    "\n",
    "    data['post_num_punc'] = data.apply(CountPostPunctuation, axis=1)\n",
    "    data['title_num_punc'] = data.apply(CountTitlePunctuation, axis=1)\n",
    "    data['post_perc_punc'] = data.post_num_punc / data.post_char_len\n",
    "    data['title_perc_punc'] = data.title_num_punc / data.title_char_len\n",
    "    data.post_perc_punc = data.post_perc_punc.fillna(0)\n",
    "    print('Earliest post = {}'.format(pd.to_datetime(data.created_utc.min(), unit=\"s\")))\n",
    "\n",
    "    # get rid of columns that aren't needed for the model\n",
    "    drop_cols = ['created_utc', 'author', 'downs', 'ups', 'score', 'id']\n",
    "    #print(data.head())\n",
    "        \n",
    "    return data.drop(drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function takes about 5 minutes to run on the whole data set, maybe 20 seconds on 20k posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing all posts before 2011.\n",
      "Earliest post = 2012-01-01 00:41:48\n",
      "There are 73724 posts after processing.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_comments</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "      <th>created_dayofweek</th>\n",
       "      <th>created_hour</th>\n",
       "      <th>created_month</th>\n",
       "      <th>created_year</th>\n",
       "      <th>post_char_len</th>\n",
       "      <th>post_num_qs</th>\n",
       "      <th>title_char_len</th>\n",
       "      <th>title_num_qs</th>\n",
       "      <th>post_num_punc</th>\n",
       "      <th>title_num_punc</th>\n",
       "      <th>post_perc_punc</th>\n",
       "      <th>title_perc_punc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I can't think straight, I can't concentrate, I...</td>\n",
       "      <td>I feel like my brain doesn't work anymore.</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>747</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>0.045515</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>There is this amazing girl that i've known sin...</td>\n",
       "      <td>She's the girl i was always looking for... But...</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>789</td>\n",
       "      <td>5</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>4</td>\n",
       "      <td>0.054499</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>I've been struggling with depression since hig...</td>\n",
       "      <td>I don't have anyone and I don't know why</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>771</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.032425</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>i burn myself..... i heat up a knife and hold ...</td>\n",
       "      <td>how often do you guys inflict self harm?</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>337</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.056380</td>\n",
       "      <td>0.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I’m scared\\n        Of myself\\n       ...</td>\n",
       "      <td>All I do is hide</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>671</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_comments                                           selftext  \\\n",
       "0             0  I can't think straight, I can't concentrate, I...   \n",
       "1             0  There is this amazing girl that i've known sin...   \n",
       "2             1  I've been struggling with depression since hig...   \n",
       "3             0  i burn myself..... i heat up a knife and hold ...   \n",
       "4             0          I’m scared\\n        Of myself\\n       ...   \n",
       "\n",
       "                                               title  created_dayofweek  \\\n",
       "0         I feel like my brain doesn't work anymore.                  4   \n",
       "1  She's the girl i was always looking for... But...                  4   \n",
       "2           I don't have anyone and I don't know why                  4   \n",
       "3           how often do you guys inflict self harm?                  4   \n",
       "4                                   All I do is hide                  4   \n",
       "\n",
       "   created_hour  created_month  created_year  post_char_len  post_num_qs  \\\n",
       "0            14              2          2014            747            1   \n",
       "1            14              2          2014            789            5   \n",
       "2            14              2          2014            771            0   \n",
       "3            13              2          2014            337            1   \n",
       "4            12              2          2014            671            0   \n",
       "\n",
       "   title_char_len  title_num_qs  post_num_punc  title_num_punc  \\\n",
       "0              42             0             34               2   \n",
       "1              72             0             43               4   \n",
       "2              40             0             25               2   \n",
       "3              40             1             19               1   \n",
       "4              16             0              0               0   \n",
       "\n",
       "   post_perc_punc  title_perc_punc  \n",
       "0        0.045515         0.047619  \n",
       "1        0.054499         0.055556  \n",
       "2        0.032425         0.050000  \n",
       "3        0.056380         0.025000  \n",
       "4        0.000000         0.000000  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean = PreProcessData(results)\n",
    "print('There are {} posts after processing.'.format(len(data_clean)))\n",
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# NLP pre-processing\n",
    "\n",
    "Create the corpus from the text post.  Limit to 20,000 to make processing easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([    0,     1,     2,     3,     4,     5,     7,     8,     9,\n",
       "               10,\n",
       "            ...\n",
       "            21208, 21209, 21210, 21211, 21212, 21213, 21214, 21215, 21216,\n",
       "            21217],\n",
       "           dtype='int64', length=20000)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean = data_clean[:20000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All processing in one function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities\n",
    "\n",
    "def CreateCorpus(raw_text) :\n",
    "    \"\"\" Create a corpus from an array of documents (each document\n",
    "        a string).  It expects it as a python object, not a pandas\n",
    "        one.  Returns an array of tokenized texts and the corpus dictionary.\n",
    "    \"\"\"\n",
    "    from gensim import corpora, models, similarities\n",
    "    from nltk.tokenize import WordPunctTokenizer\n",
    "    import string\n",
    "    from nltk.stem.snowball import SnowballStemmer\n",
    "    from nltk.corpus import stopwords\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    punctuation = set(string.punctuation)\n",
    "    word_punct_tokenizer = WordPunctTokenizer()\n",
    "    stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "    \n",
    "    texts_proc = []\n",
    "    for text in raw_text :\n",
    "        words = word_punct_tokenizer.tokenize(text)\n",
    "        words = [w for w in words if (w not in stop_words)]\n",
    "        texts_proc.append([stemmer.stem(w.lower()) for w in words \n",
    "                                if not all(c in punctuation for c in w)])\n",
    "        \n",
    "    # create dictionary\n",
    "    corpus_dictionary = corpora.Dictionary(texts_proc)\n",
    "    corpus_dictionary.filter_extremes(no_below=3, no_above=0.5)\n",
    "    print(corpus_dictionary)\n",
    "    \n",
    "    return texts_proc, corpus_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(11384 unique tokens: ['think', 'straight', 'concentr', 'feel', 'like']...)\n"
     ]
    }
   ],
   "source": [
    "# takes ~5 minutes to run\n",
    "posts_raw = list(data_clean.selftext)\n",
    "titles_raw = list(data_clean.title)\n",
    "(all_tokenized, all_dictionary) = CreateCorpus(posts_raw + titles_raw)\n",
    "posts_tokenized = all_tokenized[:len(posts_raw)]\n",
    "titles_tokenized = all_tokenized[len(posts_raw):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously (with stop words, no stemming, and extra punctuation, and all 90k posts), dictionary had 80k terms.  With all that filtering, it now has 20k terms.  With only 20k posts, it has 11k terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_vec = [all_dictionary.doc2bow(post) for post in posts_tokenized]\n",
    "titles_vec = [all_dictionary.doc2bow(post) for post in titles_tokenized]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a couple more features.  Note that the word tokenization here is pretty basic, just splitting on white space, and could definitely be improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def AddWordFeatures(dataframe, posts_raw, posts_vec, titles_raw, titles_vec) :\n",
    "    \"\"\" Add some word related features to the dataframe.\n",
    "        Arguments: X_raw is the raw data without any process.  X_vec is the vectorized\n",
    "        version of that, which has stop words and punctuation removed.\n",
    "    \"\"\"\n",
    "    dataframe_new = dataframe.copy()\n",
    "    dataframe_new = dataframe_new.assign(post_word_len1 = [len(post.split()) for post in posts_raw] )\n",
    "    dataframe_new = dataframe_new.assign(post_word_len2 = [len(post) for post in posts_vec] )\n",
    "    \n",
    "    dataframe_new = dataframe_new.assign(title_word_len1 = [len(post.split()) for post in titles_raw] )\n",
    "    dataframe_new = dataframe_new.assign(title_word_len2 = [len(post) for post in titles_vec] )\n",
    "    return dataframe_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = AddWordFeatures(data_clean, posts_raw, posts_vec, titles_raw, titles_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_comments</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "      <th>created_dayofweek</th>\n",
       "      <th>created_hour</th>\n",
       "      <th>created_month</th>\n",
       "      <th>created_year</th>\n",
       "      <th>post_char_len</th>\n",
       "      <th>post_num_qs</th>\n",
       "      <th>title_char_len</th>\n",
       "      <th>title_num_qs</th>\n",
       "      <th>post_num_punc</th>\n",
       "      <th>title_num_punc</th>\n",
       "      <th>post_perc_punc</th>\n",
       "      <th>title_perc_punc</th>\n",
       "      <th>post_word_len1</th>\n",
       "      <th>post_word_len2</th>\n",
       "      <th>title_word_len1</th>\n",
       "      <th>title_word_len2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I can't think straight, I can't concentrate, I...</td>\n",
       "      <td>I feel like my brain doesn't work anymore.</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>747</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>0.045515</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>143</td>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>There is this amazing girl that i've known sin...</td>\n",
       "      <td>She's the girl i was always looking for... But...</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>789</td>\n",
       "      <td>5</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>4</td>\n",
       "      <td>0.054499</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>162</td>\n",
       "      <td>63</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>I've been struggling with depression since hig...</td>\n",
       "      <td>I don't have anyone and I don't know why</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>771</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.032425</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>149</td>\n",
       "      <td>44</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>i burn myself..... i heat up a knife and hold ...</td>\n",
       "      <td>how often do you guys inflict self harm?</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>337</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.056380</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>65</td>\n",
       "      <td>27</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I’m scared\\n        Of myself\\n       ...</td>\n",
       "      <td>All I do is hide</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>671</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>103</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_comments                                           selftext  \\\n",
       "0             0  I can't think straight, I can't concentrate, I...   \n",
       "1             0  There is this amazing girl that i've known sin...   \n",
       "2             1  I've been struggling with depression since hig...   \n",
       "3             0  i burn myself..... i heat up a knife and hold ...   \n",
       "4             0          I’m scared\\n        Of myself\\n       ...   \n",
       "\n",
       "                                               title  created_dayofweek  \\\n",
       "0         I feel like my brain doesn't work anymore.                  4   \n",
       "1  She's the girl i was always looking for... But...                  4   \n",
       "2           I don't have anyone and I don't know why                  4   \n",
       "3           how often do you guys inflict self harm?                  4   \n",
       "4                                   All I do is hide                  4   \n",
       "\n",
       "   created_hour  created_month  created_year  post_char_len  post_num_qs  \\\n",
       "0            14              2          2014            747            1   \n",
       "1            14              2          2014            789            5   \n",
       "2            14              2          2014            771            0   \n",
       "3            13              2          2014            337            1   \n",
       "4            12              2          2014            671            0   \n",
       "\n",
       "   title_char_len  title_num_qs  post_num_punc  title_num_punc  \\\n",
       "0              42             0             34               2   \n",
       "1              72             0             43               4   \n",
       "2              40             0             25               2   \n",
       "3              40             1             19               1   \n",
       "4              16             0              0               0   \n",
       "\n",
       "   post_perc_punc  title_perc_punc  post_word_len1  post_word_len2  \\\n",
       "0        0.045515         0.047619             143              50   \n",
       "1        0.054499         0.055556             162              63   \n",
       "2        0.032425         0.050000             149              44   \n",
       "3        0.056380         0.025000              65              27   \n",
       "4        0.000000         0.000000             103              25   \n",
       "\n",
       "   title_word_len1  title_word_len2  \n",
       "0                8                5  \n",
       "1               15                7  \n",
       "2                9                2  \n",
       "3                8                5  \n",
       "4                5                2  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Semantic Analysis\n",
    "\n",
    "This is effectively PCA on the tfidf vectors to cluster them.  Use the Gensim implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(11384 unique tokens: ['think', 'straight', 'concentr', 'feel', 'like']...)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import lsimodel\n",
    "num_lsi_topics = 100\n",
    "print(all_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "post_lsi = lsimodel.LsiModel(posts_vec, num_topics=num_lsi_topics, id2word=all_dictionary)\n",
    "title_lsi = lsimodel.LsiModel(titles_vec, num_topics=num_lsi_topics, id2word=all_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ComputeDocumentLSIs(documents, lsi, N, label_base = 'lsi') : \n",
    "    \" Compute the LSI representation of every document in the corpus\"\n",
    "    baseline = [0 for x in range(N)]\n",
    "    col_labels = ['{}_{}'.format(label_base, x) for x in range(N)]\n",
    "    new_features = pd.DataFrame([], columns=col_labels)\n",
    "    for (x, text) in enumerate(documents) :\n",
    "        if len(text) > 0:\n",
    "            lsi_temp = lsi[text]\n",
    "            if len(lsi_temp) == N :\n",
    "                temp = [y for (z,y) in lsi_temp]\n",
    "                new_features.loc[x] = temp\n",
    "            else :\n",
    "                #print(x, len(temp))\n",
    "                new_features.loc[x] = baseline\n",
    "        else :\n",
    "            new_features.loc[x] = baseline\n",
    "    return new_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following has a funny issue: the title LSI features sometimes get returned as a vector with fewer dimensions than N.  For N=100, it goes as low as 93, primarily when the number of words, after stemming, is either 1 or 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 81.038747549057 seconds ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_lsi_0</th>\n",
       "      <th>post_lsi_1</th>\n",
       "      <th>post_lsi_2</th>\n",
       "      <th>post_lsi_3</th>\n",
       "      <th>post_lsi_4</th>\n",
       "      <th>post_lsi_5</th>\n",
       "      <th>post_lsi_6</th>\n",
       "      <th>post_lsi_7</th>\n",
       "      <th>post_lsi_8</th>\n",
       "      <th>post_lsi_9</th>\n",
       "      <th>...</th>\n",
       "      <th>post_lsi_90</th>\n",
       "      <th>post_lsi_91</th>\n",
       "      <th>post_lsi_92</th>\n",
       "      <th>post_lsi_93</th>\n",
       "      <th>post_lsi_94</th>\n",
       "      <th>post_lsi_95</th>\n",
       "      <th>post_lsi_96</th>\n",
       "      <th>post_lsi_97</th>\n",
       "      <th>post_lsi_98</th>\n",
       "      <th>post_lsi_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.828536</td>\n",
       "      <td>0.633567</td>\n",
       "      <td>-1.490526</td>\n",
       "      <td>0.309397</td>\n",
       "      <td>0.148669</td>\n",
       "      <td>-0.246799</td>\n",
       "      <td>-1.016607</td>\n",
       "      <td>-0.834773</td>\n",
       "      <td>-0.186845</td>\n",
       "      <td>-0.209967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226927</td>\n",
       "      <td>0.574702</td>\n",
       "      <td>0.387737</td>\n",
       "      <td>-1.072824</td>\n",
       "      <td>-0.096625</td>\n",
       "      <td>0.493620</td>\n",
       "      <td>-0.987974</td>\n",
       "      <td>0.330356</td>\n",
       "      <td>-0.070084</td>\n",
       "      <td>0.534049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.362322</td>\n",
       "      <td>0.512692</td>\n",
       "      <td>-1.460036</td>\n",
       "      <td>-1.982631</td>\n",
       "      <td>0.871212</td>\n",
       "      <td>-0.916897</td>\n",
       "      <td>2.330993</td>\n",
       "      <td>-0.057221</td>\n",
       "      <td>-1.021560</td>\n",
       "      <td>-1.260017</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.827410</td>\n",
       "      <td>0.323106</td>\n",
       "      <td>0.003248</td>\n",
       "      <td>0.552172</td>\n",
       "      <td>0.363975</td>\n",
       "      <td>0.020534</td>\n",
       "      <td>-0.016296</td>\n",
       "      <td>-0.122331</td>\n",
       "      <td>-0.772490</td>\n",
       "      <td>-0.571292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.866837</td>\n",
       "      <td>0.810607</td>\n",
       "      <td>1.073454</td>\n",
       "      <td>0.588158</td>\n",
       "      <td>1.392050</td>\n",
       "      <td>-4.053803</td>\n",
       "      <td>0.384133</td>\n",
       "      <td>-0.495249</td>\n",
       "      <td>2.520379</td>\n",
       "      <td>3.844680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109633</td>\n",
       "      <td>-0.160761</td>\n",
       "      <td>-1.016772</td>\n",
       "      <td>0.555200</td>\n",
       "      <td>0.033806</td>\n",
       "      <td>0.267345</td>\n",
       "      <td>-0.236921</td>\n",
       "      <td>-0.445109</td>\n",
       "      <td>0.216186</td>\n",
       "      <td>0.523627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.789656</td>\n",
       "      <td>0.135739</td>\n",
       "      <td>-0.020395</td>\n",
       "      <td>-0.042441</td>\n",
       "      <td>-0.303137</td>\n",
       "      <td>0.530142</td>\n",
       "      <td>0.244047</td>\n",
       "      <td>0.474679</td>\n",
       "      <td>0.432723</td>\n",
       "      <td>0.126136</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.286686</td>\n",
       "      <td>-0.180194</td>\n",
       "      <td>0.101938</td>\n",
       "      <td>-0.197686</td>\n",
       "      <td>-0.159458</td>\n",
       "      <td>-0.025053</td>\n",
       "      <td>-0.161170</td>\n",
       "      <td>-0.280319</td>\n",
       "      <td>-0.036334</td>\n",
       "      <td>-0.131410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.406624</td>\n",
       "      <td>-2.138297</td>\n",
       "      <td>-6.856583</td>\n",
       "      <td>-2.847832</td>\n",
       "      <td>-0.412536</td>\n",
       "      <td>-1.484465</td>\n",
       "      <td>3.382475</td>\n",
       "      <td>-0.734081</td>\n",
       "      <td>-5.109708</td>\n",
       "      <td>0.511395</td>\n",
       "      <td>...</td>\n",
       "      <td>0.414142</td>\n",
       "      <td>0.095096</td>\n",
       "      <td>-0.683781</td>\n",
       "      <td>-0.088795</td>\n",
       "      <td>0.174772</td>\n",
       "      <td>0.223542</td>\n",
       "      <td>0.404003</td>\n",
       "      <td>0.718277</td>\n",
       "      <td>0.053148</td>\n",
       "      <td>0.311652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_lsi_0  post_lsi_1  post_lsi_2  post_lsi_3  post_lsi_4  post_lsi_5  \\\n",
       "0    3.828536    0.633567   -1.490526    0.309397    0.148669   -0.246799   \n",
       "1    4.362322    0.512692   -1.460036   -1.982631    0.871212   -0.916897   \n",
       "2    4.866837    0.810607    1.073454    0.588158    1.392050   -4.053803   \n",
       "3    0.789656    0.135739   -0.020395   -0.042441   -0.303137    0.530142   \n",
       "4    5.406624   -2.138297   -6.856583   -2.847832   -0.412536   -1.484465   \n",
       "\n",
       "   post_lsi_6  post_lsi_7  post_lsi_8  post_lsi_9     ...       post_lsi_90  \\\n",
       "0   -1.016607   -0.834773   -0.186845   -0.209967     ...          0.226927   \n",
       "1    2.330993   -0.057221   -1.021560   -1.260017     ...         -0.827410   \n",
       "2    0.384133   -0.495249    2.520379    3.844680     ...          0.109633   \n",
       "3    0.244047    0.474679    0.432723    0.126136     ...         -0.286686   \n",
       "4    3.382475   -0.734081   -5.109708    0.511395     ...          0.414142   \n",
       "\n",
       "   post_lsi_91  post_lsi_92  post_lsi_93  post_lsi_94  post_lsi_95  \\\n",
       "0     0.574702     0.387737    -1.072824    -0.096625     0.493620   \n",
       "1     0.323106     0.003248     0.552172     0.363975     0.020534   \n",
       "2    -0.160761    -1.016772     0.555200     0.033806     0.267345   \n",
       "3    -0.180194     0.101938    -0.197686    -0.159458    -0.025053   \n",
       "4     0.095096    -0.683781    -0.088795     0.174772     0.223542   \n",
       "\n",
       "   post_lsi_96  post_lsi_97  post_lsi_98  post_lsi_99  \n",
       "0    -0.987974     0.330356    -0.070084     0.534049  \n",
       "1    -0.016296    -0.122331    -0.772490    -0.571292  \n",
       "2    -0.236921    -0.445109     0.216186     0.523627  \n",
       "3    -0.161170    -0.280319    -0.036334    -0.131410  \n",
       "4     0.404003     0.718277     0.053148     0.311652  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this takes 85 s for 20k posts and 20 topics, 154 s for 20k and 100\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "post_lsi_features = ComputeDocumentLSIs(posts_vec, post_lsi, num_lsi_topics, label_base = 'post_lsi')\n",
    "title_lsi_features = ComputeDocumentLSIs(titles_vec, title_lsi, num_lsi_topics, label_base = 'title_lsi')\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))  \n",
    "post_lsi_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create the new feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def AddLSAFeatures(data_old, post_lsi_features, title_lsi_features) :\n",
    "    \"\"\" Add the LSA features to the dataframe, remove the title and post fields.\n",
    "        Need to reset index values so no rows are dropped.\n",
    "    \"\"\"\n",
    "    data_new = data_old.copy()\n",
    "    post_lsi_features = post_lsi_features.set_index(data_new.index)\n",
    "    title_lsi_features = title_lsi_features.set_index(data_new.index)\n",
    "    data_new = data_new.join(post_lsi_features)\n",
    "    data_new = data_new.join(title_lsi_features)\n",
    "    data_new = data_new.drop(['selftext', 'title'], axis=1)\n",
    "    \n",
    "    return data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 217) (20000, 100)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_comments</th>\n",
       "      <th>created_dayofweek</th>\n",
       "      <th>created_hour</th>\n",
       "      <th>created_month</th>\n",
       "      <th>created_year</th>\n",
       "      <th>post_char_len</th>\n",
       "      <th>post_num_qs</th>\n",
       "      <th>title_char_len</th>\n",
       "      <th>title_num_qs</th>\n",
       "      <th>post_num_punc</th>\n",
       "      <th>...</th>\n",
       "      <th>title_lsi_90</th>\n",
       "      <th>title_lsi_91</th>\n",
       "      <th>title_lsi_92</th>\n",
       "      <th>title_lsi_93</th>\n",
       "      <th>title_lsi_94</th>\n",
       "      <th>title_lsi_95</th>\n",
       "      <th>title_lsi_96</th>\n",
       "      <th>title_lsi_97</th>\n",
       "      <th>title_lsi_98</th>\n",
       "      <th>title_lsi_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>747</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.116498</td>\n",
       "      <td>-0.095092</td>\n",
       "      <td>-0.081540</td>\n",
       "      <td>0.104373</td>\n",
       "      <td>-0.003097</td>\n",
       "      <td>-0.080213</td>\n",
       "      <td>0.059581</td>\n",
       "      <td>-0.061159</td>\n",
       "      <td>0.010931</td>\n",
       "      <td>-0.080847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>789</td>\n",
       "      <td>5</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028816</td>\n",
       "      <td>0.072875</td>\n",
       "      <td>0.049781</td>\n",
       "      <td>0.162898</td>\n",
       "      <td>0.201626</td>\n",
       "      <td>0.041754</td>\n",
       "      <td>0.059803</td>\n",
       "      <td>-0.104414</td>\n",
       "      <td>0.079218</td>\n",
       "      <td>-0.058239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>771</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022695</td>\n",
       "      <td>-0.008500</td>\n",
       "      <td>0.007467</td>\n",
       "      <td>-0.003130</td>\n",
       "      <td>-0.058134</td>\n",
       "      <td>0.004793</td>\n",
       "      <td>-0.033829</td>\n",
       "      <td>-0.009283</td>\n",
       "      <td>-0.013911</td>\n",
       "      <td>0.001754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>337</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.066376</td>\n",
       "      <td>-0.349864</td>\n",
       "      <td>0.039773</td>\n",
       "      <td>-0.034748</td>\n",
       "      <td>-0.173236</td>\n",
       "      <td>-0.161002</td>\n",
       "      <td>0.124001</td>\n",
       "      <td>0.005649</td>\n",
       "      <td>-0.052677</td>\n",
       "      <td>-0.100002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>671</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004772</td>\n",
       "      <td>0.010931</td>\n",
       "      <td>0.007441</td>\n",
       "      <td>-0.000831</td>\n",
       "      <td>0.008094</td>\n",
       "      <td>-0.004701</td>\n",
       "      <td>0.003350</td>\n",
       "      <td>-0.019895</td>\n",
       "      <td>-0.005237</td>\n",
       "      <td>-0.000790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_comments  created_dayofweek  created_hour  created_month  created_year  \\\n",
       "0             0                  4            14              2          2014   \n",
       "1             0                  4            14              2          2014   \n",
       "2             1                  4            14              2          2014   \n",
       "3             0                  4            13              2          2014   \n",
       "4             0                  4            12              2          2014   \n",
       "\n",
       "   post_char_len  post_num_qs  title_char_len  title_num_qs  post_num_punc  \\\n",
       "0            747            1              42             0             34   \n",
       "1            789            5              72             0             43   \n",
       "2            771            0              40             0             25   \n",
       "3            337            1              40             1             19   \n",
       "4            671            0              16             0              0   \n",
       "\n",
       "       ...       title_lsi_90  title_lsi_91  title_lsi_92  title_lsi_93  \\\n",
       "0      ...          -0.116498     -0.095092     -0.081540      0.104373   \n",
       "1      ...          -0.028816      0.072875      0.049781      0.162898   \n",
       "2      ...           0.022695     -0.008500      0.007467     -0.003130   \n",
       "3      ...          -0.066376     -0.349864      0.039773     -0.034748   \n",
       "4      ...           0.004772      0.010931      0.007441     -0.000831   \n",
       "\n",
       "   title_lsi_94  title_lsi_95  title_lsi_96  title_lsi_97  title_lsi_98  \\\n",
       "0     -0.003097     -0.080213      0.059581     -0.061159      0.010931   \n",
       "1      0.201626      0.041754      0.059803     -0.104414      0.079218   \n",
       "2     -0.058134      0.004793     -0.033829     -0.009283     -0.013911   \n",
       "3     -0.173236     -0.161002      0.124001      0.005649     -0.052677   \n",
       "4      0.008094     -0.004701      0.003350     -0.019895     -0.005237   \n",
       "\n",
       "   title_lsi_99  \n",
       "0     -0.080847  \n",
       "1     -0.058239  \n",
       "2      0.001754  \n",
       "3     -0.100002  \n",
       "4     -0.000790  \n",
       "\n",
       "[5 rows x 217 columns]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean2 = AddLSAFeatures(data_clean, post_lsi_features, title_lsi_features)\n",
    "print(data_clean2.shape, post_lsi_features.shape)\n",
    "data_clean2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEACAYAAAC9Gb03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADiZJREFUeJzt3UGIFml+x/HfbzWawSEKjgyNStrNdCRN+rBscA65vANL\naBkcl8mSVSTg4ioG3FMf0gt7Ciw7e5jDDjEZehkxh0QjEhaNLub0IgEPOntRI0IzuNgeYnYHBCWD\n9O4/B19nXzvdWm+9VV1v/fv7gYGp532q6pGH/lH866kqR4QAAHl9pekBAADqRdADQHIEPQAkR9AD\nQHIEPQAkR9ADQHIEPQAkR9ADQHIEPQAkR9ADQHLrmx6AJL3xxhsxPj5eat8nT55o06ZN1Q4II4m5\nXhuY5+I+/fTTX0XEtlf1azTobe+TtO+tt97SjRs3Sh2j2+2q0+lUOi6MJuZ6bWCei7P9yyL9Gi3d\nRMTFiDi2efPmJocBAKlRoweA5Ah6AEiu0aC3vc/23KNHj5ocBgCkRo0eAJKjdAMAyRH0AJDcSDww\nNYybDx7p8OylpofxgnsfvNv0EADgS1zRA0ByrLoBgOQaLd1ExEVJFzeOTRwdL1l+mZmqdkwAkA2l\nGwBIjqAHgOQIegBIrvXLK0dR2fsNr8KyTQBlcEUPAMmNxIdH1m8Za3IYAJDaSLzU7Cu/z2fDAKAu\nlG4AIDmCHgCSI+gBIDmCHgCSI+gBIDmCHgCS48nYFhnmiVueqgXWLh6YAoDkeGAKAJKjRg8AyRH0\nAJAcQQ8AyRH0AJAcQQ8AybGOfo0YdA0+6+6BPLiiB4DkCHoASI6gB4DkCHoASI6gB4DkKg96239i\n+2Pb523/TdXHBwAMplDQ2z5l+6HtW0vap23ftT1ve1aSIuJORByX9FeS/rz6IQMABlH0iv60pOn+\nBtvrJJ2UtFfSpKSDtid7v70n6ZKky5WNFABQSqEHpiLiqu3xJc17JM1HxGeSZPuspP2S/isiLki6\nYPuSpH+pbrhYLUUesOKhKqAdhnkydruk+33bC5Lett2R9L6kjXrJFb3tY5KOSdKWrds0M7VYahBv\nvqbS+2I43W53Vc/3+PHjVT8nVh/zXL3KX4EQEV1J3QL95iTNSdLGsYn48Ga5ocxMLarsvhjOvUOd\nVT1ft9tVp7O658TqY56rN0xCPpC0s297R6+tMD4lCAD1G2Z55XVJE7Z32d4g6YCkC4McgE8JAkD9\nii6vPCPpmqTdthdsH4mIRUknJF2RdEfSuYi4Xd9QAQBlFF11c3CF9ssaYgklpZt2e9XKHFblAKOh\n0VcgULoBgPrxrhsASK7RdYmUbgCgfpRuACA5SjcAkBxBDwDJUaMHgOSo0QNAcrwNDLXhgSpgNFCj\nB4DkqNEDQHLU6AEgOWr0aMxKNXxq90C1qNEDQHIEPQAkx81YAEiOm7EAkBylGwBIjqAHgOQIegBI\njnX0GDnLra9nbT1QHlf0AJAcyysBIDmWVwJAcpRuACA5bsaiFcZnL2lmalGH+27UcoMWKIYregBI\njqAHgOQIegBIjho9WosHq4BiuKIHgOQIegBIjidjASA5nowFgOQo3QBAcqy6QSpLV+KwCgfgih4A\n0iPoASA5gh4AkiPoASA5gh4AkiPoASA5llciNZZbAlzRA0B6tVzR2/6mpHcl/YGkTyLiP+o4DzAo\nrvCxFhW+ord9yvZD27eWtE/bvmt73vasJEXEzyLiqKTjkr5d7ZABAIMYpHRzWtJ0f4PtdZJOStor\naVLSQduTfV1+0PsdANCQwkEfEVclfb6keY+k+Yj4LCKeSjorab+f+bGkn0fEL6obLgBgUMPW6LdL\nut+3vSDpbUnfk/QNSZttvxURHy/d0fYxScckacvWbZqZWiw1gDdfU+l90S51zHW32630eBje48eP\nmZeK1XIzNiI+kvTRK/rMSZqTpI1jE/HhzXJDmZlaVNl90S51zPW9Q51Kj4fhdbtddTqdpoeRyrB/\nNQ8k7ezb3tFrA1qhfxUOK3CQ1bDr6K9LmrC9y/YGSQckXSi6s+19tud++8WTIYcBAFjJIMsrz0i6\nJmm37QXbRyJiUdIJSVck3ZF0LiJuFz0mnxIEgPoVLt1ExMEV2i9Lulzm5HwcHKOEMg6yavQuZkRc\nlHRx49jE0SbHASzFE7TIhHfdAEByBD0AJNdo6YYaPdrieSmHEg7aqNErelbdAED9KN0AQHKUboAB\nsAQTbUTpBgCSo3QDAMnx2kegJMo4aAuu6AEgOW7GAkBy3IwFKjA+e+n/vR8HGBWUboCaEP4YFQQ9\nACRH0ANActyMBYDkuBkLAMlRugGA5Ah6AEiOoAdWGcsusdoIegBIjqAHgORYXgnUjO/NomksrwQa\nsrRWT+0edeF99MAqIcTRFGr0AJAcV/RAhaq4ah+fvUQ9H5Ui6IGGUdJB3SjdAEByBD0AJEfQA0By\nPDAFAMnxwBQAJEfpBgCSI+iBEcTrEFAlgh4AkiPogRHGlT2qQNADQHIEPdASXN2jLIIeAJIj6AEg\nOYIeAJIj6AEgOYIeaBluyGJQlQe97a/a/sT2+aqPDQAYXKGgt33K9kPbt5a0T9u+a3ve9qwkRcRn\nEXGkjsECeDmu9rGcolf0pyVN9zfYXifppKS9kiYlHbQ9WenoAABDKxT0EXFV0udLmvdImu9dwT+V\ndFbS/orHBwAY0jAfHtku6X7f9oKkt21vlfRDSV+z/f2I+NFyO9s+JumYJG3Zuk0zU4ulBvHmayq9\nL9plLc91t9t94d/e7XaX7Tcztbjib23x+PHj1v8bRk3lX5iKiF9LOl6g35ykOUnaODYRH94sN5SZ\nqUWV3Rftspbn+t6hjg731d/vHeos2+/w7KUVf2uLbrerTqfT9DBSGeav5oGknX3bO3pthfEpQaCc\n/puu9z54t8GRoA2GWV55XdKE7V22N0g6IOnCIAfgU4IAUL+iyyvPSLomabftBdtHImJR0glJVyTd\nkXQuIm7XN1QAQBlFV90cjIixiPi9iNgREZ/02i9HxB9HxB9FxA8HPbntfbbnfvvFk0F3BdCz3OuL\nB32l8Up9WZefQ6OvQKB0AwD14103AJBco0FP6QYoZpgSSpl9KdnkQukGAJKjdAMAyRH0AJAcNXog\nmbL19ef7vWx/avftRI0eAJKjdAMAyRH0AJAcNXogieXq50Xq7q86BtqPGj0AJEfpBgCSI+gBIDmC\nHgCS42YssAZV8ZI0bty2BzdjASA5SjcAkBxBDwDJEfQAkBxBDwDJEfQAkNz6Jk9ue5+kfeu3jDU5\nDGBNeNm7cIY95r0P3n2hrX/7ZfsW6YfhsbwSAJKjdAMAyRH0AJAcQQ8AyRH0AJAcQQ8AyRH0AJAc\nQQ8AyRH0AJAcHx4B1qhXPRVb1QdGlu7fvz0+e4kPmKwCnowFgOQo3QBAcgQ9ACRH0ANAcgQ9ACRH\n0ANAcgQ9ACRH0ANAcgQ9ACRH0ANAcgQ9ACS3vuoD2t4k6R8kPZXUjYh/rvocAIDiCl3R2z5l+6Ht\nW0vap23ftT1ve7bX/L6k8xFxVNJ7FY8XADCgoqWb05Km+xtsr5N0UtJeSZOSDtqelLRD0v1et99U\nM0wAQFmFgj4irkr6fEnzHknzEfFZRDyVdFbSfkkLehb2hY8PAKiPI6JYR3tc0r9HxJ/2tr8laToi\nvtvb/mtJb0v6W0l/L+kLSf+5Uo3e9jFJxyRpy9ZtX/+7n/y01D/gzdek//7fUruiZZjr5kxt36yb\nDx6tuL1SH0lftvVvv2z/XZvX6fXXX3+h33LHWun35/+/3Ln6f1vapyqDHG/Yc7/zzjufRsSfvapf\n5TdjI+KJpO8U6DcnaU6SNo5NxIc3yw1lZmpRZfdFuzDXzbl3qKPDfR8IWbq9Uh9JX7b1b79s/9PT\nm9TpdF7ot9yxVvr9+f8vd67+35b2qcogx6v63CsZprTyQNLOvu0dvTYAwAgZJuivS5qwvcv2BkkH\nJF0Y5AB8ShAA6ld0eeUZSdck7ba9YPtIRCxKOiHpiqQ7ks5FxO1BTs6nBAGgfoUKnhFxcIX2y5Iu\nlz257X2S9q3fMlb2EACAV+Dj4ACQHOvcASA5gh4Akmt0UTI1egCoX+EnY2sdhP0/kn7Z17RZ0qNl\nui7X/oakX9U0tLJWGn+Txx103yL9h+0zyDxLozfXa2Wei/Rjnlf3uM/3/cOI2PbK3hExcv9Jmiva\nLulG0+MtOv4mjzvovkX6D9tnkHkexbleK/NcpB/zPNrzPKo1+osDto+ausY5zHEH3bdI/2H7MM/V\nH7eOeS7Sj3le3eMOtO9IlG6GYftGFHipD9qPuV4bmOfqjeoV/SDmmh4AVg1zvTYwzxVr/RU9AODl\nMlzRAwBegqAHgOQIegBILl3Q295k+59s/9T2oabHg3rY/qrtT2yfb3osqI/tb/b+lv/V9l80PZ62\nakXQ2z5l+6HtW0vap23ftT1ve7bX/L6k8xFxVNJ7qz5YlDbIPMezj9IfaWakGMaA8/yz3t/ycUnf\nbmK8GbQi6CWdljTd32B7naSTkvZKmpR00Paknn3S8H6v229WcYwY3mkVn2e012kNPs8/6P2OEloR\n9BFxVdLnS5r3SJrvXdk9lXRW0n5JC3oW9lJL/n14ZsB5RksNMs9+5seSfh4Rv1jtsWbR5iDcrt9d\nuUvPAn67pH+T9Je2/1HtecQaK1t2nm1vtf2xpK/Z/n4zQ0OFVvp7/p6kb0j6lu3jTQwsg0ZfU1yH\niHgi6TtNjwP1iohf61ndFolFxEeSPmp6HG3X5iv6B5J29m3v6LUhF+Z5bWCea9TmoL8uacL2Ltsb\nJB2QdKHhMaF6zPPawDzXqBVBb/uMpGuSdttesH0kIhYlnZB0RdIdSeci4naT48RwmOe1gXlefbzU\nDACSa8UVPQCgPIIeAJIj6AEgOYIeAJIj6AEgOYIeAJIj6AEgOYIeAJIj6AEguf8DdlUj/b8CoRoA\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa683f9c2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_clean2.num_comments.hist(bins=311)\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib.pyplot' has no attribute 'xticklabel'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-574-8729d52622ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticklabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2-3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'4+'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib.pyplot' has no attribute 'xticklabel'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEOCAYAAABxdpuaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa62788f668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "comment_bins = [0, 1, 2, 4, 400]\n",
    "#comment_bins = [-1, 0.5, 1.5, 3.5, 400]\n",
    "plt.hist(data_clean2.num_comments, bins=comment_bins)\n",
    "plt.xlim([0, 20])\n",
    "plt.xlabel('Number of Comments in Bin')\n",
    "plt.ylabel('Count')\n",
    "plt.xscale('log')\n",
    "plt.xlim([0.5, 8])\n",
    "plt.xticklabel(['0', '1', '2-3', '4+'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def BinNumComments(df, bins) :\n",
    "    \"\"\" Bin the number of comments into the specified number of bins\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    df_new = df.copy()\n",
    "    categorized = pd.cut(df_new.num_comments, bins=bins, labels = False, include_lowest = True)\n",
    "    df_new = df_new.assign(comment_category=categorized)\n",
    "       \n",
    "    return df_new.drop('num_comments', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_dayofweek</th>\n",
       "      <th>created_hour</th>\n",
       "      <th>created_month</th>\n",
       "      <th>created_year</th>\n",
       "      <th>post_char_len</th>\n",
       "      <th>post_num_qs</th>\n",
       "      <th>title_char_len</th>\n",
       "      <th>title_num_qs</th>\n",
       "      <th>post_num_punc</th>\n",
       "      <th>title_num_punc</th>\n",
       "      <th>...</th>\n",
       "      <th>title_lsi_91</th>\n",
       "      <th>title_lsi_92</th>\n",
       "      <th>title_lsi_93</th>\n",
       "      <th>title_lsi_94</th>\n",
       "      <th>title_lsi_95</th>\n",
       "      <th>title_lsi_96</th>\n",
       "      <th>title_lsi_97</th>\n",
       "      <th>title_lsi_98</th>\n",
       "      <th>title_lsi_99</th>\n",
       "      <th>comment_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>747</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.095092</td>\n",
       "      <td>-0.081540</td>\n",
       "      <td>0.104373</td>\n",
       "      <td>-0.003097</td>\n",
       "      <td>-0.080213</td>\n",
       "      <td>0.059581</td>\n",
       "      <td>-0.061159</td>\n",
       "      <td>0.010931</td>\n",
       "      <td>-0.080847</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>789</td>\n",
       "      <td>5</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072875</td>\n",
       "      <td>0.049781</td>\n",
       "      <td>0.162898</td>\n",
       "      <td>0.201626</td>\n",
       "      <td>0.041754</td>\n",
       "      <td>0.059803</td>\n",
       "      <td>-0.104414</td>\n",
       "      <td>0.079218</td>\n",
       "      <td>-0.058239</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>771</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008500</td>\n",
       "      <td>0.007467</td>\n",
       "      <td>-0.003130</td>\n",
       "      <td>-0.058134</td>\n",
       "      <td>0.004793</td>\n",
       "      <td>-0.033829</td>\n",
       "      <td>-0.009283</td>\n",
       "      <td>-0.013911</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>337</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.349864</td>\n",
       "      <td>0.039773</td>\n",
       "      <td>-0.034748</td>\n",
       "      <td>-0.173236</td>\n",
       "      <td>-0.161002</td>\n",
       "      <td>0.124001</td>\n",
       "      <td>0.005649</td>\n",
       "      <td>-0.052677</td>\n",
       "      <td>-0.100002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>671</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010931</td>\n",
       "      <td>0.007441</td>\n",
       "      <td>-0.000831</td>\n",
       "      <td>0.008094</td>\n",
       "      <td>-0.004701</td>\n",
       "      <td>0.003350</td>\n",
       "      <td>-0.019895</td>\n",
       "      <td>-0.005237</td>\n",
       "      <td>-0.000790</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   created_dayofweek  created_hour  created_month  created_year  \\\n",
       "0                  4            14              2          2014   \n",
       "1                  4            14              2          2014   \n",
       "2                  4            14              2          2014   \n",
       "3                  4            13              2          2014   \n",
       "4                  4            12              2          2014   \n",
       "\n",
       "   post_char_len  post_num_qs  title_char_len  title_num_qs  post_num_punc  \\\n",
       "0            747            1              42             0             34   \n",
       "1            789            5              72             0             43   \n",
       "2            771            0              40             0             25   \n",
       "3            337            1              40             1             19   \n",
       "4            671            0              16             0              0   \n",
       "\n",
       "   title_num_punc        ...         title_lsi_91  title_lsi_92  title_lsi_93  \\\n",
       "0               2        ...            -0.095092     -0.081540      0.104373   \n",
       "1               4        ...             0.072875      0.049781      0.162898   \n",
       "2               2        ...            -0.008500      0.007467     -0.003130   \n",
       "3               1        ...            -0.349864      0.039773     -0.034748   \n",
       "4               0        ...             0.010931      0.007441     -0.000831   \n",
       "\n",
       "   title_lsi_94  title_lsi_95  title_lsi_96  title_lsi_97  title_lsi_98  \\\n",
       "0     -0.003097     -0.080213      0.059581     -0.061159      0.010931   \n",
       "1      0.201626      0.041754      0.059803     -0.104414      0.079218   \n",
       "2     -0.058134      0.004793     -0.033829     -0.009283     -0.013911   \n",
       "3     -0.173236     -0.161002      0.124001      0.005649     -0.052677   \n",
       "4      0.008094     -0.004701      0.003350     -0.019895     -0.005237   \n",
       "\n",
       "   title_lsi_99  comment_category  \n",
       "0     -0.080847                 0  \n",
       "1     -0.058239                 0  \n",
       "2      0.001754                 0  \n",
       "3     -0.100002                 0  \n",
       "4     -0.000790                 0  \n",
       "\n",
       "[5 rows x 217 columns]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_binned = BinNumComments(data_clean2, comment_bins)\n",
    "data_binned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble, linear_model\n",
    "\n",
    "class BuildClassificationModel() :\n",
    "    \n",
    "    def __init__(self, data_x, data_y, model_type = 'randomforest', test_frac = 0.2) :\n",
    "        from sklearn import ensemble, linear_model\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        from sklearn.svm import SVC\n",
    "        \n",
    "        (self.train_x, self.test_x, self.train_y, self.test_y) = train_test_split(\n",
    "                    data_x, data_y, test_size = test_frac)\n",
    "                \n",
    "        if model_type == 'randomforest' :\n",
    "            self.model = ensemble.RandomForestClassifier()\n",
    "        elif model_type == 'gradientboostingclassifier' :\n",
    "            self.model = ensemble.GradientBoostingClassifier()\n",
    "        elif model_type == 'logisticregression' :\n",
    "            self.model = linear_model.LogisticRegression()\n",
    "        elif model_type == 'svc' :\n",
    "            self.model = SVC(kernel='rbf', C=1e3, gamma=0.1)\n",
    "        else :\n",
    "            print('Model type \"{}\" is not defined'.format(model_type))\n",
    "            return\n",
    "\n",
    "        print('{} on {} features.  Training on {} rows, validating on {}.'.format(model_type, self.train_x.shape[1], self.train_x.shape[0], self.test_x.shape[0]))\n",
    "        self.model.fit(self.train_x, self.train_y)\n",
    "        return\n",
    "    \n",
    "    def predict(self) :\n",
    "        print('Accuracy: %.3f' % self.model.score(self.test_x, self.test_y))            \n",
    "\n",
    "        \n",
    "def TestClassificationModels(train_x, train_y, models_to_test, log_flag = False) :\n",
    "    \"Train model on the models supplied in models_to_test\"\n",
    "    models = []\n",
    "    for model in models_to_test :\n",
    "        model_temp = BuildClassificationModel(train_x, train_y, model_type = model)\n",
    "        model_temp.predict()\n",
    "        models.append(model_temp)\n",
    "        print()\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomforest on 216 features.  Training on 16000 rows, validating on 4000.\n",
      "\n",
      "randomforest\n",
      "Accuracy: 0.353\n",
      "gradientboostingclassifier on 216 features.  Training on 16000 rows, validating on 4000.\n",
      "\n",
      "gradientboostingclassifier\n",
      "Accuracy: 0.429\n",
      "logisticregression on 216 features.  Training on 16000 rows, validating on 4000.\n",
      "\n",
      "logisticregression\n",
      "Accuracy: 0.426\n",
      "svc on 216 features.  Training on 16000 rows, validating on 4000.\n",
      "\n",
      "svc\n",
      "Accuracy: 0.412\n"
     ]
    }
   ],
   "source": [
    "models_to_test = ['randomforest', 'gradientboostingclassifier', 'logisticregression', 'svc']\n",
    "train_x = data_binned.drop('comment_category', axis=1)\n",
    "train_y = data_binned.comment_category\n",
    "\n",
    "models = TestClassificationModels(train_x, train_y, models_to_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create pipeline for webapp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logisticregression on 216 features.  Training on 16000 rows, validating on 4000.\n",
      "Accuracy: 0.430\n"
     ]
    }
   ],
   "source": [
    "model_binned_1_logreg = BuildClassificationModel(train_x, train_y, 'logisticregression')\n",
    "model_binned_1_logreg.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_binned_1_logreg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cnf_matrix = confusion_matrix(model_binned_1_logreg.test_y, \n",
    "         model_binned_1_logreg.model.predict(model_binned_1_logreg.test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    import itertools\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[ 0.87798896  0.00245248  0.00429185  0.11526671]\n",
      " [ 0.7983871   0.0016129   0.00322581  0.19677419]\n",
      " [ 0.79694019  0.          0.00278164  0.20027816]\n",
      " [ 0.71650485  0.          0.00485437  0.27864078]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAEmCAYAAADr3bIaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wHdRP3L/vZU8gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa628be45f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['0', '1', '2-3', '4+'], normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model_binned_1_logreg, open('Model_binned_1_logreg_class.p', 'wb'))\n",
    "pickle.dump(model_binned_1_logreg.model, open('Model_binned_1_logreg_model.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ProcessingVariables() :\n",
    "    \"Class to easily store all variables needed for processing\"\n",
    "    def __init__(self, num_lsi_topics, post_lsi, title_lsi, dictionary, comment_bins) :\n",
    "        self.num_lsi_topics = num_lsi_topics\n",
    "        self.post_lsi = post_lsi\n",
    "        self.title_lsi = title_lsi\n",
    "        self.comment_bins = comment_bins\n",
    "        self.dictionary = dictionary\n",
    "\n",
    "\n",
    "    def extract_all(self) :\n",
    "        return (self.num_lsi_topics, self.post_lsi, \n",
    "                self.title_lsi, self.dictionary, self.comment_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_binned_1_processing = ProcessingVariables(num_lsi_topics, \n",
    "            post_lsi, title_lsi, all_dictionary, comment_bins)\n",
    "pickle.dump(model_binned_1_processing, open('Model_binned_1_processing', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n",
      "<class 'gensim.models.lsimodel.LsiModel'>\n",
      "<class 'gensim.models.lsimodel.LsiModel'>\n",
      "<class 'gensim.corpora.dictionary.Dictionary'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "test = pickle.load(open('Model_binned_1_processing', 'rb'))\n",
    "(a, b, c, d, e) = test.extract_all()\n",
    "for t in (a, b, c, d, e) :\n",
    "    print(type(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SaveProcessingVariables(base_name, num_lsi_topics, post_lsi, title_lsi, dictionary, comment_bins) :\n",
    "    \"function to store all processing variables in separate files\"\n",
    "    \n",
    "    file_name = '{}_num_lsi_topics.p'.format(base_name)\n",
    "    pickle.dump(num_lsi_topics, open(file_name, 'wb'))\n",
    "    \n",
    "    file_name = '{}_post_lsi.p'.format(base_name)\n",
    "    pickle.dump(post_lsi, open(file_name, 'wb'))\n",
    "    \n",
    "    file_name = '{}_title_lsi.p'.format(base_name)\n",
    "    pickle.dump(title_lsi, open(file_name, 'wb'))\n",
    "    \n",
    "    file_name = '{}_dictionary.p'.format(base_name)\n",
    "    pickle.dump(dictionary, open(file_name, 'wb'))\n",
    "    \n",
    "    file_name = '{}_comment_bins.p'.format(base_name)\n",
    "    pickle.dump(comment_bins, open(file_name, 'wb'))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "SaveProcessingVariables('Model_binned_1', num_lsi_topics, post_lsi, title_lsi, all_dictionary, comment_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, <gensim.models.lsimodel.LsiModel object at 0x7fa627dac0b8>, <gensim.models.lsimodel.LsiModel object at 0x7fa627dac080>, <gensim.corpora.dictionary.Dictionary object at 0x7fa627dacc50>, [0, 1, 2, 4, 400], LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))\n"
     ]
    }
   ],
   "source": [
    "def LoadParameters(model_file_name = 'Model_binned_1_logreg_model.p', \n",
    "                   processing_file_name = 'Model_binned_1_processing') :\n",
    "    \"Load variables needed to process a single post\"\n",
    "    import pickle\n",
    "    temp = pickle.load(open(processing_file_name, 'rb'))\n",
    "    (num_lsi_topics, post_lsi, title_lsi, all_dictionary, \n",
    "         comment_bins) = temp.extract_all()\n",
    "    model = pickle.load(open(model_file_name, 'rb'))\n",
    "    \n",
    "    return (num_lsi_topics, post_lsi, title_lsi, all_dictionary, \n",
    "         comment_bins, model)\n",
    "\n",
    "print(LoadParameters('Model_binned_1_logreg_model.p', 'Model_binned_1_processing'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PreProcessData(title, post, post_time) :\n",
    "    \"\"\" This processes user entered data.  All input parameters are strings.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    date = time.strptime(s, r\"%m/%d/%Y %I:%M:%S %p\")\n",
    "    data = pd.DataFrame({\n",
    "        'title': title, \n",
    "        'selftext': post, \n",
    "        'created_dayofweek': date.tm_wday,\n",
    "        'created_hour': date.tm_hour,\n",
    "        'created_month': date.tm_mon,\n",
    "        'created_year': 2014,\n",
    "        }, index=[0])\n",
    "        \n",
    "    data['post_char_len'] = data.selftext.apply(lambda x: len(x))\n",
    "    data['post_num_qs'] = data.selftext.apply(lambda x: x.count('?'))\n",
    "    data['title_char_len'] = data.title.apply(lambda x: len(x))\n",
    "    data['title_num_qs'] = data.title.apply(lambda x: x.count('?'))\n",
    "    \n",
    "    def CountPostPunctuation(row) :\n",
    "        # count the number of punctuation in the selftext\n",
    "        import string\n",
    "        punc_set = set(string.punctuation)\n",
    "        num_punc = 0\n",
    "        for char in row['selftext'] :\n",
    "            if char in punc_set :\n",
    "                num_punc += 1\n",
    "        return num_punc\n",
    "    def CountTitlePunctuation(row) :\n",
    "        # count the number of punctuation in the selftext\n",
    "        import string\n",
    "        punc_set = set(string.punctuation)\n",
    "        num_punc = 0\n",
    "        for char in row['title'] :\n",
    "            if char in punc_set :\n",
    "                num_punc += 1\n",
    "        return num_punc\n",
    "\n",
    "    data['post_num_punc'] = data.apply(CountPostPunctuation, axis=1)\n",
    "    data['title_num_punc'] = data.apply(CountTitlePunctuation, axis=1)\n",
    "    data['post_perc_punc'] = data.post_num_punc / data.post_char_len\n",
    "    data['title_perc_punc'] = data.title_num_punc / data.title_char_len\n",
    "    data.post_perc_punc = data.post_perc_punc.fillna(0)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.DataFrame({\n",
    "        'title': test_title, \n",
    "        'selftext': test_post\n",
    "        }, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProcessText(df, post, title, dictionary, post_lsi, title_lsi) :\n",
    "    \"\"\" Process text fields to create all features.\n",
    "        Returns an dataframe containing the new features.\n",
    "    \"\"\"\n",
    "\n",
    "    def helper(text, dictionary, lsi) :\n",
    "        \"process just one text\"\n",
    "        #from gensim import corpora, models, similarities\n",
    "        from nltk.tokenize import WordPunctTokenizer\n",
    "        import string\n",
    "        from nltk.stem.snowball import SnowballStemmer\n",
    "        from nltk.corpus import stopwords\n",
    "\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        punctuation = set(string.punctuation)\n",
    "        word_punct_tokenizer = WordPunctTokenizer()\n",
    "        stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "\n",
    "        words = word_punct_tokenizer.tokenize(text)\n",
    "        words = [w for w in words if (w not in stop_words)]\n",
    "        text_tokenized = [stemmer.stem(word.lower()) for word in words]\n",
    "        text_vec = dictionary.doc2bow(text_tokenized)\n",
    "                \n",
    "        text_features = lsi[text_vec]\n",
    "        if len(text_features) == lsi.num_topics :\n",
    "            text_features = [y for (z,y) in text_features]\n",
    "        else :\n",
    "            text_features = [0 for x in range(lsi.num_topics)]\n",
    "    \n",
    "        return text_tokenized, text_vec, text_features\n",
    "    \n",
    "    (post_tokenized, post_vec, post_features) = helper(post, dictionary, post_lsi) \n",
    "    (title_tokenized, title_vec, title_features) = helper(title, dictionary, title_lsi) \n",
    "    \n",
    "    df_new = df.copy()\n",
    "    df_new = df_new.assign(post_word_len1 = len(post.split()))\n",
    "    df_new = df_new.assign(post_word_len2 = len(post))\n",
    "    df_new = df_new.assign(title_word_len1 = len(title.split()))\n",
    "    df_new = df_new.assign(title_word_len2 = len(title))\n",
    "    \n",
    "    post_col_names = ['post_lsi_{}'.format(x) for x in range(len(post_features))]\n",
    "    post_features = pd.DataFrame(data=[post_features], columns=post_col_names, index=[0])\n",
    "    df_new = df_new.join(post_features)\n",
    "\n",
    "    title_col_names = ['title_lsi_{}'.format(x) for x in range(len(title_features))]\n",
    "    title_features = pd.DataFrame(data=[title_features], columns=title_col_names, index=[0])\n",
    "    df_new = df_new.join(pd.DataFrame(title_features, index=[0]))\n",
    "                           \n",
    "    df_new = df_new.drop(['selftext', 'title'], axis=1)\n",
    "                           \n",
    "    def AddLSAFeatures(data_old, post_lsi_features, title_lsi_features) :\n",
    "        \"\"\" Add the LSA features to the dataframe, remove the title and post fields.\n",
    "            Need to reset index values so no rows are dropped.\n",
    "        \"\"\"\n",
    "        data_new = data_old.copy()\n",
    "        post_lsi_features = post_lsi_features.set_index(data_new.index)\n",
    "        title_lsi_features = title_lsi_features.set_index(data_new.index)\n",
    "        data_new = data_new.join(post_lsi_features)\n",
    "        data_new = data_new.join(title_lsi_features)\n",
    "        data_new = data_new.drop(['selftext', 'title'], axis=1)\n",
    "\n",
    "        return data_new\n",
    "                           \n",
    "\n",
    "    def ComputeDocumentLSIs(documents, lsi, N, label_base = 'lsi') : \n",
    "        \" Compute the LSI representation of every document in the corpus\"\n",
    "        baseline = [0 for x in range(N)]\n",
    "        col_labels = ['{}_{}'.format(label_base, x) for x in range(N)]\n",
    "        new_features = pd.DataFrame([], columns=col_labels)\n",
    "        for (x, text) in enumerate(documents) :\n",
    "            if len(text) > 0:\n",
    "                lsi_temp = lsi[text]\n",
    "                if len(lsi_temp) == N :\n",
    "                    temp = [y for (z,y) in lsi_temp]\n",
    "                    new_features.loc[x] = temp\n",
    "                else :\n",
    "                    #print(x, len(temp))\n",
    "                    new_features.loc[x] = baseline\n",
    "            else :\n",
    "                new_features.loc[x] = baseline\n",
    "        return new_features\n",
    "\n",
    "                           \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = 5\n",
    "test_title = results[index]['title']\n",
    "test_post = results[index]['selftext']\n",
    "test_time = pd.to_datetime(results[index]['created_utc'], unit=\"s\").__str__() + ' AM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_dayofweek</th>\n",
       "      <th>created_hour</th>\n",
       "      <th>created_month</th>\n",
       "      <th>created_year</th>\n",
       "      <th>post_char_len</th>\n",
       "      <th>post_num_qs</th>\n",
       "      <th>title_char_len</th>\n",
       "      <th>title_num_qs</th>\n",
       "      <th>post_num_punc</th>\n",
       "      <th>title_num_punc</th>\n",
       "      <th>...</th>\n",
       "      <th>title_lsi_90</th>\n",
       "      <th>title_lsi_91</th>\n",
       "      <th>title_lsi_92</th>\n",
       "      <th>title_lsi_93</th>\n",
       "      <th>title_lsi_94</th>\n",
       "      <th>title_lsi_95</th>\n",
       "      <th>title_lsi_96</th>\n",
       "      <th>title_lsi_97</th>\n",
       "      <th>title_lsi_98</th>\n",
       "      <th>title_lsi_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>2014</td>\n",
       "      <td>729</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011998</td>\n",
       "      <td>0.077903</td>\n",
       "      <td>-0.002321</td>\n",
       "      <td>0.025899</td>\n",
       "      <td>-0.019282</td>\n",
       "      <td>-0.079719</td>\n",
       "      <td>-0.051448</td>\n",
       "      <td>0.092041</td>\n",
       "      <td>0.09908</td>\n",
       "      <td>-0.076621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 216 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   created_dayofweek  created_hour  created_month  created_year  \\\n",
       "0                  2            14              9          2014   \n",
       "\n",
       "   post_char_len  post_num_qs  title_char_len  title_num_qs  post_num_punc  \\\n",
       "0            729            0              30             1             30   \n",
       "\n",
       "   title_num_punc      ...       title_lsi_90  title_lsi_91  title_lsi_92  \\\n",
       "0               1      ...           0.011998      0.077903     -0.002321   \n",
       "\n",
       "   title_lsi_93  title_lsi_94  title_lsi_95  title_lsi_96  title_lsi_97  \\\n",
       "0      0.025899     -0.019282     -0.079719     -0.051448      0.092041   \n",
       "\n",
       "   title_lsi_98  title_lsi_99  \n",
       "0       0.09908     -0.076621  \n",
       "\n",
       "[1 rows x 216 columns]"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = PreProcessData(test_title, test_post, test_time)\n",
    "df2 = ProcessText(df1, test_post, test_title, all_dictionary, post_lsi, title_lsi)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent matching = 100.00%\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for (x,y) in zip(data_binned.columns, df2.columns) :\n",
    "    if x != y :\n",
    "        print('no match!')\n",
    "    else :\n",
    "        i += 1\n",
    "print('Percent matching = {:.2f}%'.format(i/len(df2.columns)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2014-02-14 11:53:59'"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.to_datetime(test_utc, unit=\"s\").__str__()\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ClassifyPost(title, post, time_stamp) :\n",
    "    \"\"\"Takes post information and classifies it according to the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    (num_lsi_topics, post_lsi, title_lsi, all_dictionary, \n",
    "         comment_bins, model) = LoadParameters()\n",
    "    \n",
    "    df = PreProcessData(title, post, time_stamp)\n",
    "    df = ProcessText(df, post, title, all_dictionary, post_lsi, title_lsi)\n",
    "    \n",
    "    #print(df.head())\n",
    "    \n",
    "    # model.predict(df)\n",
    "    return model.predict(df)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's just a matter of feeding the information into the function and letting it go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(ClassifyPost(test_title, test_post, test_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_binned.comment_category.iloc[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0; model [0], post 1\n",
      "0; model [0], post 1\n",
      "0; model [0], post 1\n",
      "0; model [0], post 3\n",
      "0; model [0], post 0\n",
      "2; model [3], post 1\n",
      "0; model [0], post 3\n",
      "0; model [0], post 1\n",
      "0; model [0], post 3\n",
      "0; model [0], post 0\n"
     ]
    }
   ],
   "source": [
    "data_x = data_binned.drop('comment_category', axis=1)\n",
    "for index in range(10) :\n",
    "    test_title = results[index]['title']\n",
    "    test_post = results[index]['selftext']\n",
    "    test_time = pd.to_datetime(results[index]['created_utc'], unit=\"s\").__str__()\n",
    "\n",
    "    prediction = ClassifyPost(test_title, test_post, test_time)\n",
    "    raw_prediction = model_binned_1_logreg.model.predict(data_x.iloc[index].values.reshape(1, -1))\n",
    "    print('{}; model {}, post {}'.format(data_binned.comment_category.iloc[index],\n",
    "                                         raw_prediction, \n",
    "                                         prediction, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_binned_1_logreg.model.C"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
